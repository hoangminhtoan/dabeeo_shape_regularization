{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop polygon from mask image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. From Contours\n",
    "\n",
    "That can contains many contours in one single image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Create a single mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "import shutil \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM_LEVEL = '18'\n",
    "PARENT_DIR = f'data/test/output'\n",
    "INPUT_DIR = f'{PARENT_DIR}/{ZOOM_LEVEL}'\n",
    "OUTPUT_DIR = f'{PARENT_DIR}/{ZOOM_LEVEL}_all/'\n",
    "IMG_NAME = f'prediction_gan_{ZOOM_LEVEL}'\n",
    "\n",
    "os.makedirs(os.path.join(OUTPUT_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 2042.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move all tiles from seperate folders into a single folder\n",
    "# for _, x in enumerate(os.listdir(INPUT_DIR)):\n",
    "#     for y in os.listdir(os.path.join(INPUT_DIR, x)):\n",
    "#         shutil.copy(os.path.join(INPUT_DIR, x, y),\n",
    "#                     os.path.join(OUTPUT_DIR, f'{ZOOM_LEVEL}_{x}_{y}'))\n",
    "        \n",
    "# Merge all tile image into a single image\n",
    "img_list = {}\n",
    "for img_file in tqdm(sorted(os.listdir(OUTPUT_DIR)), total=len(os.listdir(OUTPUT_DIR))):\n",
    "    zoom_level, x, y = img_file.replace('.png', '').strip().split('_')\n",
    "    if x not in img_list:\n",
    "        img_list[x] = []\n",
    "    img = cv2.imread(os.path.join(OUTPUT_DIR, img_file))\n",
    "    img_list[x].append(img)\n",
    "\n",
    "img_vs = []\n",
    "for k, values in img_list.items():\n",
    "    img_v = cv2.vconcat(values)\n",
    "    img_vs.append(img_v)\n",
    "\n",
    "img = cv2.hconcat(img_vs)\n",
    "cv2.imwrite(f\"{PARENT_DIR}/{IMG_NAME}.png\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Detect Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img_path):\n",
    "    image = cv2.imread(img_path, 0)\n",
    "    _, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(image, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_list = []\n",
    "    rect_list = []\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        rect = cv2.boundingRect(cnt)\n",
    "        x,y,w,h = rect\n",
    "        rect_list.append(rect)\n",
    "        with open(f'{img_path}.txt', 'a') as f:\n",
    "            f.write(f'{idx}\\t{rect}\\n')\n",
    "        bbox = image[y: y+h, x: x+w]\n",
    "        h, w = bbox.shape\n",
    "        if h < 256 and w < 256:\n",
    "            img = np.zeros((256, 256))\n",
    "            offset_x = 0 if 128 - w // 2 <= 0 else 128 - w // 2\n",
    "            offset_y = 0 if 128 - h // 2 <= 0 else 128 - h // 2\n",
    "            img[offset_y:  offset_y + h, offset_x: offset_x + w] = bbox\n",
    "        if h > 256 or w > 256:\n",
    "            img = cv2.resize(bbox, (256, 256))\n",
    "        _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        image_list.append(img)\n",
    "\n",
    "    return rect_list, image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM_LEVEL = '19'\n",
    "DIR1 = f'20230413/prediction_masks/prediction_masks_{ZOOM_LEVEL}_mask_test.png'\n",
    "DIR2 = f'20230413/arcpy_masks/arcpy_masks_{ZOOM_LEVEL}_mask_test.png'\n",
    "OUT_DIR1 = f'20230413/prediction_masks/cropped/{ZOOM_LEVEL}'\n",
    "OUT_DIR2 = f'20230413/arcpy_masks/cropped/{ZOOM_LEVEL}'\n",
    "OUT_DIR3 = f'20230413/predict2arcpy/test'\n",
    "\n",
    "rect_list1, image_list1 = find_contours(DIR1)\n",
    "rect_list2, image_list2 = find_contours(DIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1, rect1 in enumerate(rect_list1):\n",
    "    pt1 = (rect1[0], rect1[1])\n",
    "    for idx2, rect2 in enumerate(rect_list2):\n",
    "        pt2 = (rect2[0], rect2[1])\n",
    "        if np.sqrt(abs(pt1[0] - pt2[0]) ** 2 + abs(pt1[1] - pt2[1]) ** 2) < 8:\n",
    "            with open(f'20230413/mapping_test.txt', 'a') as f:\n",
    "                f.write(f'{idx1}\\t{idx2}\\t{rect_list1[idx1]}\\t{rect_list2[idx2]}\\n')\n",
    "            cv2.imwrite(os.path.join(OUT_DIR1, f\"pred_mask_{ZOOM_LEVEL}_{idx1}.png\"), image_list1[idx1])\n",
    "            cv2.imwrite(os.path.join(OUT_DIR2, f\"ideal_mask_{ZOOM_LEVEL}_{idx1}.png\"), image_list2[idx2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Merge two masks into one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in sorted(os.listdir(OUT_DIR1)):\n",
    "    suffix = img_file.split('mask')[-1]\n",
    "    idx = int(img_file.split('_')[-1].replace('.png', ''))\n",
    "    img1 = cv2.imread(os.path.join(OUT_DIR1, img_file))\n",
    "    img2 = cv2.imread(os.path.join(OUT_DIR2, f'ideal_mask{suffix}'))\n",
    "    img = cv2.hconcat([img1, img2])\n",
    "    cv2.imwrite(os.path.join(OUT_DIR3, f\"mask_{idx:05}.png\"), img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. From Tif file\n",
    "\n",
    "* Create Tif file from Geojson file\n",
    "* Crop each polygon based on .geojson and .tif files\n",
    "* Each single image contains only one polygon shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Simple creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_label</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>POLYGON ((126.87264 37.52606, 126.87264 37.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>POLYGON ((126.86843 37.52606, 126.86838 37.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>POLYGON ((126.87043 37.52606, 126.87036 37.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>POLYGON ((126.86241 37.52606, 126.86233 37.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>POLYGON ((126.86096 37.52644, 126.86096 37.526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id class_label                                           geometry\n",
       "0  0    BUILDING  POLYGON ((126.87264 37.52606, 126.87264 37.526...\n",
       "1  1    BUILDING  POLYGON ((126.86843 37.52606, 126.86838 37.526...\n",
       "2  2    BUILDING  POLYGON ((126.87043 37.52606, 126.87036 37.526...\n",
       "3  3    BUILDING  POLYGON ((126.86241 37.52606, 126.86233 37.526...\n",
       "4  4    BUILDING  POLYGON ((126.86096 37.52644, 126.86096 37.526..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rasterio\n",
    "import rasterio.mask\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# Read roofs\n",
    "gdf = gpd.read_file(\"data/prediction_shape_v2.geojson\")  # Your roofs\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             geometry\n",
      "id                                                   \n",
      "0   POLYGON ((126.87264 37.52606, 126.87264 37.526...\n",
      "1   POLYGON ((126.86843 37.52606, 126.86838 37.526...\n",
      "2   POLYGON ((126.87043 37.52606, 126.87036 37.526...\n",
      "3   POLYGON ((126.86241 37.52606, 126.86233 37.526...\n",
      "4   POLYGON ((126.86096 37.52644, 126.86096 37.526...\n"
     ]
    }
   ],
   "source": [
    "df = gpd.GeoDataFrame(gdf, columns=['id', 'geometry'])\n",
    "df = df.set_index('id')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index(\"roof_id\")\n",
    "# roof = df.loc[2]  # Your roof id\n",
    "\n",
    "\n",
    "# Open input raster and write masked (clipped) output raster\n",
    "with rasterio.open(\"data/arcpy_shape_v2.tif\") as src:\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, [row[\"geometry\"]], crop=True, filled=True)\n",
    "            out_meta = src.meta\n",
    "\n",
    "            out_meta.update(\n",
    "                {\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_transform,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            with rasterio.open(f\"data/outputs_arcpy/mask_{str(idx).zfill(5)}.tif\", \"w\", **out_meta) as dest:\n",
    "                dest.write(out_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception as {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Get same polygon by calculating IOU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.mask\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(df_path):\n",
    "    df = gpd.read_file(df_path)\n",
    "    df = gpd.GeoDataFrame(df, columns=['id', 'geometry'])\n",
    "    df = df.set_index('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df = read_data(\"20230417/train_v3/prediction_masks_train_v3.geojson\")\n",
    "arcpy_df = read_data(\"20230417/train_v3/arcpy_masks_train_v3.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543\n",
      "1532\n"
     ]
    }
   ],
   "source": [
    "print(len(pp_df.index))\n",
    "print(len(arcpy_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_polygon(tif_path, idx1, idx2, row, output_path):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        try:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, [row[\"geometry\"]], crop=True, filled=True)\n",
    "            out_meta = src.meta\n",
    "\n",
    "            out_meta.update(\n",
    "                {\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_transform,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            with rasterio.open(f\"{output_path}/mask_{str(idx1).zfill(5)}_{str(idx2).zfill(5)}.tif\", \"w\", **out_meta) as dest:\n",
    "                dest.write(out_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception as {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1, pp_row in pp_df.iterrows():\n",
    "    polygon1 = pp_row['geometry']\n",
    "    for idx2, arcpy_row in arcpy_df.iterrows():\n",
    "        polygon2 = arcpy_row['geometry']\n",
    "\n",
    "        if polygon1.intersects(polygon2):\n",
    "            iou = polygon1.intersection(polygon2).area / polygon1.union(polygon2).area \n",
    "            if iou > 0.9:\n",
    "                with open(\"20230417/train_v3/train_mapping.txt\", 'a') as fin:\n",
    "                    fin.write(f\"pp: idx1 = {idx1}\\t arcpy: idx2 = {idx2}\\n\")\n",
    "                save_polygon(\"20230417/train_v3/prediction_masks_18.tif\", idx1, idx2, pp_row, \"20230417/train_v3/prediction_masks/cropped/18\")\n",
    "                save_polygon(\"20230417/train_v3/arcpy_masks_18.tif\", idx1, idx2, arcpy_row, \"20230417/train_v3/arcpy_masks/cropped/18\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Merge two masks into one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [00:00<00:00, 1015.66it/s]\n"
     ]
    }
   ],
   "source": [
    "A_dir = '20230417/train_v3/prediction_masks/cropped/18'\n",
    "B_dir = '20230417/train_v3/arcpy_masks/cropped/18'\n",
    "out_dir = '20230417/train_v3/train_v3'\n",
    "\n",
    "for img_file in tqdm(os.listdir(A_dir), total=len(os.listdir(A_dir))):\n",
    "    imageA = cv2.imread(os.path.join(A_dir, img_file), 0)\n",
    "    imageB = cv2.imread(os.path.join(B_dir, img_file), 0)\n",
    "\n",
    "    hA, wA = imageA.shape\n",
    "    hB, wB = imageB.shape\n",
    "\n",
    "    if (hA < 256 and wA < 256) and (hB < 256 and wB < 256):\n",
    "        imgA = np.zeros((256, 256))\n",
    "        imgB = np.zeros((256, 256))\n",
    "        offset_x = 0 if 128 - wA // 2 < 0 else 128 - wA // 2\n",
    "        offset_y = 0 if 128 - hA // 2 < 0 else 128 - hA // 2\n",
    "        imgA[offset_y:offset_y + hA, offset_x:offset_x + wA] = imageA\n",
    "        offset_x = 0 if 128 - wB // 2 < 0 else 128 - wB // 2\n",
    "        offset_y = 0 if 128 - hB // 2 < 0 else 128 - hB // 2\n",
    "        imgB[offset_y:offset_y + hB, offset_x:offset_x + wB] = imageB\n",
    "    else:\n",
    "        imgA = cv2.resize(imageA, (256, 256))\n",
    "        imgB = cv2.resize(imageB, (256, 256))\n",
    "    \n",
    "    cv2.imwrite(os.path.join(out_dir, img_file.replace('mask', 'mask_3_').replace('.tif', '.png')), cv2.hconcat([imgA, imgB]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "\n",
    "img_list = {}\n",
    "\n",
    "train_folders = ['20230417/train_v1/train_v1', '20230417/train_v2/train_v2', '20230417/train_v3/train_v3']\n",
    "\n",
    "for train_folder in train_folders:\n",
    "    for img_name in os.listdir(os.path.join(train_folder)):\n",
    "        img_list[img_name] = cv2.imread(os.path.join(train_folder, img_name))\n",
    "\n",
    "s = pd.Series(img_list)\n",
    "train_data, val_data = [i.to_dict() for i in train_test_split(s, train_size=0.9)]\n",
    "\n",
    "for k, value in train_data.items():\n",
    "    cv2.imwrite(os.path.join('20230417/train', k), value)\n",
    "\n",
    "for k, value in val_data.items():\n",
    "    cv2.imwrite(os.path.join('20230417/val', k), value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in os.listdir('20230417/test/prediction_masks/18_all'):\n",
    "    imgA = cv2.imread(os.path.join('20230417/test/prediction_masks/18_all', img_file), 0)\n",
    "    imgB = cv2.imread(os.path.join('20230417/test/arcpy_masks/18_all', img_file), 0)\n",
    "    cv2.imwrite(os.path.join('20230417/test/test', img_file), cv2.hconcat([imgA, imgB]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Cut out raster file based on geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read roof\n",
    "arcpy_df = read_data(\"20230417/test/arcpy_masks_test_suwon.geojson\")\n",
    "\n",
    "for idx, row in arcpy_df.iterrows():\n",
    "    # Open input raster and write masked (clipped) output raster\n",
    "    with rasterio.open(\"20230417/test/rgb/rgb_18.tif\") as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [row[\"geometry\"]], crop=True)\n",
    "        out_meta = src.meta\n",
    "\n",
    "        out_meta.update(\n",
    "            {\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        with rasterio.open(f\"20230417/test/rgb/cropped/18/rgb_{str(idx).zfill(5)}.tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toan_gdal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
